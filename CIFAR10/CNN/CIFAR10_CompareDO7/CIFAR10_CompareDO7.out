0it [00:00, ?it/s]  0%|          | 0/170498071 [00:01<?, ?it/s]  0%|          | 8192/170498071 [00:01<58:48, 48318.93it/s]  0%|          | 40960/170498071 [00:01<45:37, 62260.45it/s]  0%|          | 90112/170498071 [00:01<34:54, 81360.19it/s]  0%|          | 221184/170498071 [00:01<25:32, 111118.88it/s]  0%|          | 450560/170498071 [00:01<18:29, 153291.65it/s]  1%|          | 909312/170498071 [00:02<13:13, 213738.30it/s]  1%|          | 1826816/170498071 [00:02<09:21, 300136.74it/s]  2%|▏         | 3661824/170498071 [00:02<06:31, 425767.97it/s]  3%|▎         | 4382720/170498071 [00:02<04:40, 593134.06it/s]  4%|▍         | 6774784/170498071 [00:02<03:16, 834408.63it/s]  5%|▌         | 9216000/170498071 [00:02<02:17, 1173906.87it/s]  6%|▋         | 10723328/170498071 [00:02<01:39, 1612443.67it/s]  8%|▊         | 12935168/170498071 [00:02<01:11, 2218599.49it/s]  9%|▉         | 15278080/170498071 [00:03<00:51, 3032600.08it/s] 10%|▉         | 16957440/170498071 [00:03<00:38, 3939529.15it/s] 11%|█         | 19046400/170498071 [00:03<00:29, 5182186.69it/s] 13%|█▎        | 21454848/170498071 [00:03<00:22, 6702108.51it/s] 14%|█▎        | 23273472/170498071 [00:03<00:18, 7788067.31it/s] 15%|█▍        | 25501696/170498071 [00:03<00:14, 9670267.90it/s] 16%|█▌        | 27402240/170498071 [00:03<00:12, 11337835.79it/s] 17%|█▋        | 29245440/170498071 [00:03<00:11, 12254305.89it/s] 18%|█▊        | 31006720/170498071 [00:03<00:10, 13483026.99it/s] 19%|█▉        | 32759808/170498071 [00:04<00:10, 13660647.33it/s] 21%|██        | 35414016/170498071 [00:04<00:08, 15452072.36it/s] 22%|██▏       | 37240832/170498071 [00:04<00:08, 15250192.72it/s] 23%|██▎       | 38961152/170498071 [00:04<00:08, 15319171.23it/s] 24%|██▍       | 41558016/170498071 [00:04<00:07, 17097937.75it/s] 25%|██▌       | 43433984/170498071 [00:04<00:07, 16506938.26it/s] 27%|██▋       | 45203456/170498071 [00:04<00:07, 16045021.71it/s] 28%|██▊       | 47652864/170498071 [00:04<00:06, 17733827.80it/s] 29%|██▉       | 49545216/170498071 [00:04<00:07, 16861524.84it/s] 30%|███       | 51322880/170498071 [00:05<00:07, 16424290.46it/s] 31%|███▏      | 53551104/170498071 [00:05<00:06, 17555227.61it/s] 32%|███▏      | 55377920/170498071 [00:05<00:06, 16977961.93it/s] 34%|███▎      | 57171968/170498071 [00:05<00:06, 16880802.13it/s] 35%|███▍      | 59318272/170498071 [00:05<00:06, 17879916.51it/s] 36%|███▌      | 61153280/170498071 [00:05<00:06, 16098216.11it/s] 37%|███▋      | 63414272/170498071 [00:05<00:06, 17547773.18it/s] 38%|███▊      | 65495040/170498071 [00:05<00:05, 18261513.61it/s] 40%|███▉      | 67387392/170498071 [00:06<00:06, 15947911.88it/s] 41%|████      | 69672960/170498071 [00:06<00:05, 17534163.38it/s] 42%|████▏     | 71933952/170498071 [00:06<00:05, 18120949.65it/s] 43%|████▎     | 73834496/170498071 [00:06<00:05, 16192366.26it/s] 45%|████▍     | 76193792/170498071 [00:06<00:05, 17874006.29it/s] 46%|████▌     | 78110720/170498071 [00:06<00:05, 18130596.09it/s] 47%|████▋     | 80011264/170498071 [00:06<00:05, 15907970.94it/s] 48%|████▊     | 82599936/170498071 [00:06<00:04, 17957136.55it/s] 50%|████▉     | 84566016/170498071 [00:06<00:05, 16469811.80it/s] 51%|█████     | 86360064/170498071 [00:07<00:05, 16181919.80it/s] 52%|█████▏    | 88825856/170498071 [00:07<00:04, 17974912.44it/s] 53%|█████▎    | 90759168/170498071 [00:07<00:04, 16721788.84it/s] 54%|█████▍    | 92545024/170498071 [00:07<00:04, 15955578.08it/s] 56%|█████▌    | 95051776/170498071 [00:07<00:04, 17257296.97it/s] 57%|█████▋    | 96886784/170498071 [00:07<00:04, 17413683.63it/s] 58%|█████▊    | 98697216/170498071 [00:07<00:04, 16376001.29it/s] 59%|█████▉    | 101294080/170498071 [00:07<00:03, 17792517.52it/s] 61%|██████    | 103153664/170498071 [00:08<00:03, 17560343.90it/s] 62%|██████▏   | 104964096/170498071 [00:08<00:03, 16513661.64it/s] 63%|██████▎   | 107438080/170498071 [00:08<00:03, 17948100.14it/s] 64%|██████▍   | 109305856/170498071 [00:08<00:03, 17645886.59it/s] 65%|██████▌   | 111124480/170498071 [00:08<00:03, 16583135.65it/s] 66%|██████▋   | 113270784/170498071 [00:08<00:03, 17342746.58it/s] 67%|██████▋   | 115056640/170498071 [00:08<00:03, 17258678.74it/s] 69%|██████▊   | 117104640/170498071 [00:08<00:02, 17977616.21it/s] 70%|██████▉   | 119119872/170498071 [00:08<00:02, 18282776.34it/s] 71%|███████   | 120971264/170498071 [00:09<00:03, 16278586.75it/s] 72%|███████▏  | 123199488/170498071 [00:09<00:02, 17708596.97it/s] 73%|███████▎  | 125263872/170498071 [00:09<00:02, 18429263.30it/s] 75%|███████▍  | 127172608/170498071 [00:09<00:02, 16429536.96it/s] 76%|███████▌  | 129146880/170498071 [00:09<00:02, 17166639.44it/s] 77%|███████▋  | 131571712/170498071 [00:09<00:02, 18805654.07it/s] 78%|███████▊  | 133545984/170498071 [00:09<00:02, 16722193.76it/s] 79%|███████▉  | 135438336/170498071 [00:09<00:02, 17307153.75it/s] 81%|████████  | 137256960/170498071 [00:09<00:01, 17515723.82it/s] 82%|████████▏ | 139067392/170498071 [00:10<00:01, 17441987.51it/s] 83%|████████▎ | 141049856/170498071 [00:10<00:01, 18092737.08it/s] 84%|████████▍ | 142901248/170498071 [00:10<00:01, 17442974.14it/s] 85%|████████▍ | 144744448/170498071 [00:10<00:01, 17168536.88it/s] 86%|████████▌ | 146497536/170498071 [00:10<00:01, 17261366.44it/s] 87%|████████▋ | 148242432/170498071 [00:10<00:01, 17132598.17it/s] 88%|████████▊ | 150429696/170498071 [00:10<00:01, 18321802.58it/s] 89%|████████▉ | 152297472/170498071 [00:10<00:01, 17875354.18it/s] 90%|█████████ | 154116096/170498071 [00:10<00:00, 17438072.25it/s] 91%|█████████▏| 155885568/170498071 [00:11<00:00, 16783957.91it/s] 92%|█████████▏| 157605888/170498071 [00:11<00:00, 16902821.10it/s] 94%|█████████▍| 159916032/170498071 [00:11<00:00, 18367597.32it/s] 95%|█████████▍| 161800192/170498071 [00:11<00:00, 18207702.29it/s] 96%|█████████▌| 163659776/170498071 [00:11<00:00, 16826456.34it/s] 97%|█████████▋| 165625856/170498071 [00:11<00:00, 17585829.13it/s] 98%|█████████▊| 167436288/170498071 [00:11<00:00, 17733550.85it/s] 99%|█████████▉| 169287680/170498071 [00:11<00:00, 17815493.08it/s]Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cifar10/cifar-10-python.tar.gz
Extracting ./data_cifar10/cifar-10-python.tar.gz to ./data_cifar10/
Files already downloaded and verified
train_dataset =  40000
valid_dataset =  10000
test_dataset =  10000
Default(NoDropOut) training start ...
170500096it [00:30, 17815493.08it/s]                               Epoch [1/50], Loss: 0.0221, val_loss: 0.0202, val_acc: 0.5438
Epoch [2/50], Loss: 0.0145, val_loss: 0.0128, val_acc: 0.7210
Epoch [3/50], Loss: 0.0111, val_loss: 0.0111, val_acc: 0.7636
Epoch [4/50], Loss: 0.0091, val_loss: 0.0105, val_acc: 0.7765
Epoch [5/50], Loss: 0.0074, val_loss: 0.0124, val_acc: 0.7462
Epoch [6/50], Loss: 0.0062, val_loss: 0.0092, val_acc: 0.8122
Epoch [7/50], Loss: 0.0052, val_loss: 0.0091, val_acc: 0.8148
Epoch [8/50], Loss: 0.0044, val_loss: 0.0090, val_acc: 0.8215
Epoch [9/50], Loss: 0.0037, val_loss: 0.0107, val_acc: 0.8066
Epoch [10/50], Loss: 0.0031, val_loss: 0.0108, val_acc: 0.8093
Epoch [11/50], Loss: 0.0028, val_loss: 0.0091, val_acc: 0.8288
Epoch [12/50], Loss: 0.0024, val_loss: 0.0106, val_acc: 0.8213
Epoch [13/50], Loss: 0.0020, val_loss: 0.0093, val_acc: 0.8319
Epoch [14/50], Loss: 0.0017, val_loss: 0.0112, val_acc: 0.8211
Epoch [15/50], Loss: 0.0017, val_loss: 0.0101, val_acc: 0.8298
Epoch [16/50], Loss: 0.0015, val_loss: 0.0102, val_acc: 0.8331
Epoch [17/50], Loss: 0.0013, val_loss: 0.0130, val_acc: 0.8024
Epoch [18/50], Loss: 0.0013, val_loss: 0.0106, val_acc: 0.8317
Epoch [19/50], Loss: 0.0012, val_loss: 0.0104, val_acc: 0.8316
Epoch [20/50], Loss: 0.0012, val_loss: 0.0108, val_acc: 0.8168
Epoch [21/50], Loss: 0.0010, val_loss: 0.0119, val_acc: 0.8173
Epoch [22/50], Loss: 0.0010, val_loss: 0.0104, val_acc: 0.8319
Epoch [23/50], Loss: 0.0010, val_loss: 0.0104, val_acc: 0.8362
Epoch [24/50], Loss: 0.0009, val_loss: 0.0117, val_acc: 0.8175
Epoch [25/50], Loss: 0.0008, val_loss: 0.0111, val_acc: 0.8349
Epoch [26/50], Loss: 0.0009, val_loss: 0.0105, val_acc: 0.8412
Epoch [27/50], Loss: 0.0009, val_loss: 0.0108, val_acc: 0.8414
Epoch [28/50], Loss: 0.0008, val_loss: 0.0118, val_acc: 0.8246
Epoch [29/50], Loss: 0.0009, val_loss: 0.0103, val_acc: 0.8432
Epoch [30/50], Loss: 0.0008, val_loss: 0.0122, val_acc: 0.8168
Epoch [31/50], Loss: 0.0008, val_loss: 0.0107, val_acc: 0.8378
Epoch [32/50], Loss: 0.0006, val_loss: 0.0104, val_acc: 0.8410
Epoch [33/50], Loss: 0.0008, val_loss: 0.0109, val_acc: 0.8367
Epoch [34/50], Loss: 0.0008, val_loss: 0.0105, val_acc: 0.8372
Epoch [35/50], Loss: 0.0008, val_loss: 0.0106, val_acc: 0.8369
Epoch [36/50], Loss: 0.0008, val_loss: 0.0120, val_acc: 0.8261
Epoch [37/50], Loss: 0.0008, val_loss: 0.0116, val_acc: 0.8246
Epoch [38/50], Loss: 0.0007, val_loss: 0.0095, val_acc: 0.8488
Epoch [39/50], Loss: 0.0007, val_loss: 0.0106, val_acc: 0.8427
Epoch [40/50], Loss: 0.0008, val_loss: 0.0110, val_acc: 0.8378
Epoch [41/50], Loss: 0.0007, val_loss: 0.0103, val_acc: 0.8461
Epoch [42/50], Loss: 0.0009, val_loss: 0.0109, val_acc: 0.8271
Epoch [43/50], Loss: 0.0008, val_loss: 0.0120, val_acc: 0.8207
Epoch [44/50], Loss: 0.0007, val_loss: 0.0105, val_acc: 0.8414
Epoch [45/50], Loss: 0.0007, val_loss: 0.0108, val_acc: 0.8395
Epoch [46/50], Loss: 0.0007, val_loss: 0.0110, val_acc: 0.8325
Epoch [47/50], Loss: 0.0008, val_loss: 0.0110, val_acc: 0.8303
Epoch [48/50], Loss: 0.0007, val_loss: 0.0112, val_acc: 0.8246
Epoch [49/50], Loss: 0.0007, val_loss: 0.0099, val_acc: 0.8459
Epoch [50/50], Loss: 0.0007, val_loss: 0.0110, val_acc: 0.8331
test_accuracy: 82.81 %
learning time: 791.156 [sec]
1DropOut training start ...
Epoch [1/50], Loss: 0.0250, val_loss: 0.0203, val_acc: 0.5330
Epoch [2/50], Loss: 0.0173, val_loss: 0.0157, val_acc: 0.6535
Epoch [3/50], Loss: 0.0138, val_loss: 0.0143, val_acc: 0.7057
Epoch [4/50], Loss: 0.0115, val_loss: 0.0112, val_acc: 0.7580
Epoch [5/50], Loss: 0.0098, val_loss: 0.0112, val_acc: 0.7581
Epoch [6/50], Loss: 0.0084, val_loss: 0.0105, val_acc: 0.7805
Epoch [7/50], Loss: 0.0073, val_loss: 0.0108, val_acc: 0.7742
Epoch [8/50], Loss: 0.0063, val_loss: 0.0105, val_acc: 0.7958
Epoch [9/50], Loss: 0.0056, val_loss: 0.0093, val_acc: 0.8151
Epoch [10/50], Loss: 0.0050, val_loss: 0.0122, val_acc: 0.7762
Epoch [11/50], Loss: 0.0043, val_loss: 0.0097, val_acc: 0.8182
Epoch [12/50], Loss: 0.0038, val_loss: 0.0100, val_acc: 0.8156
Epoch [13/50], Loss: 0.0033, val_loss: 0.0109, val_acc: 0.8098
Epoch [14/50], Loss: 0.0031, val_loss: 0.0120, val_acc: 0.7986
Epoch [15/50], Loss: 0.0027, val_loss: 0.0096, val_acc: 0.8319
Epoch [16/50], Loss: 0.0024, val_loss: 0.0111, val_acc: 0.8121
Epoch [17/50], Loss: 0.0023, val_loss: 0.0101, val_acc: 0.8304
Epoch [18/50], Loss: 0.0020, val_loss: 0.0102, val_acc: 0.8268
Epoch [19/50], Loss: 0.0019, val_loss: 0.0131, val_acc: 0.8019
Epoch [20/50], Loss: 0.0018, val_loss: 0.0120, val_acc: 0.8121
Epoch [21/50], Loss: 0.0017, val_loss: 0.0106, val_acc: 0.8266
Epoch [22/50], Loss: 0.0016, val_loss: 0.0094, val_acc: 0.8439
Epoch [23/50], Loss: 0.0014, val_loss: 0.0132, val_acc: 0.8172
Epoch [24/50], Loss: 0.0014, val_loss: 0.0105, val_acc: 0.8339
Epoch [25/50], Loss: 0.0012, val_loss: 0.0117, val_acc: 0.8299
Epoch [26/50], Loss: 0.0012, val_loss: 0.0109, val_acc: 0.8381
Epoch [27/50], Loss: 0.0013, val_loss: 0.0120, val_acc: 0.8233
Epoch [28/50], Loss: 0.0012, val_loss: 0.0134, val_acc: 0.8066
Epoch [29/50], Loss: 0.0012, val_loss: 0.0107, val_acc: 0.8427
Epoch [30/50], Loss: 0.0012, val_loss: 0.0110, val_acc: 0.8371
Epoch [31/50], Loss: 0.0011, val_loss: 0.0117, val_acc: 0.8262
Epoch [32/50], Loss: 0.0011, val_loss: 0.0121, val_acc: 0.8300
Epoch [33/50], Loss: 0.0010, val_loss: 0.0110, val_acc: 0.8377
Epoch [34/50], Loss: 0.0012, val_loss: 0.0105, val_acc: 0.8368
Epoch [35/50], Loss: 0.0011, val_loss: 0.0123, val_acc: 0.8226
Epoch [36/50], Loss: 0.0011, val_loss: 0.0123, val_acc: 0.8225
Epoch [37/50], Loss: 0.0011, val_loss: 0.0121, val_acc: 0.8224
Epoch [38/50], Loss: 0.0010, val_loss: 0.0109, val_acc: 0.8338
Epoch [39/50], Loss: 0.0010, val_loss: 0.0115, val_acc: 0.8303
Epoch [40/50], Loss: 0.0009, val_loss: 0.0120, val_acc: 0.8258
Epoch [41/50], Loss: 0.0010, val_loss: 0.0113, val_acc: 0.8410
Epoch [42/50], Loss: 0.0010, val_loss: 0.0125, val_acc: 0.8107
Epoch [43/50], Loss: 0.0010, val_loss: 0.0115, val_acc: 0.8309
Epoch [44/50], Loss: 0.0010, val_loss: 0.0117, val_acc: 0.8254
Epoch [45/50], Loss: 0.0011, val_loss: 0.0129, val_acc: 0.8196
Epoch [46/50], Loss: 0.0009, val_loss: 0.0139, val_acc: 0.8152
Epoch [47/50], Loss: 0.0011, val_loss: 0.0111, val_acc: 0.8384
Epoch [48/50], Loss: 0.0011, val_loss: 0.0104, val_acc: 0.8411
Epoch [49/50], Loss: 0.0010, val_loss: 0.0106, val_acc: 0.8430
Epoch [50/50], Loss: 0.0009, val_loss: 0.0119, val_acc: 0.8306
test_accuracy: 83.21 %
learning time: 793.910 [sec]
2DropOuts training start ...
Epoch [1/50], Loss: 0.0320, val_loss: 0.0285, val_acc: 0.2643
Epoch [2/50], Loss: 0.0294, val_loss: 0.0269, val_acc: 0.3105
Epoch [3/50], Loss: 0.0277, val_loss: 0.0288, val_acc: 0.2416
Epoch [4/50], Loss: 0.0264, val_loss: 0.0238, val_acc: 0.3914
Epoch [5/50], Loss: 0.0249, val_loss: 0.0220, val_acc: 0.4693
Epoch [6/50], Loss: 0.0234, val_loss: 0.0201, val_acc: 0.5215
Epoch [7/50], Loss: 0.0220, val_loss: 0.0195, val_acc: 0.4976
Epoch [8/50], Loss: 0.0209, val_loss: 0.0176, val_acc: 0.5978
Epoch [9/50], Loss: 0.0202, val_loss: 0.0164, val_acc: 0.6264
Epoch [10/50], Loss: 0.0190, val_loss: 0.0169, val_acc: 0.6139
Epoch [11/50], Loss: 0.0181, val_loss: 0.0161, val_acc: 0.6597
Epoch [12/50], Loss: 0.0178, val_loss: 0.0158, val_acc: 0.6494
Epoch [13/50], Loss: 0.0165, val_loss: 0.0166, val_acc: 0.6328
Epoch [14/50], Loss: 0.0166, val_loss: 0.0151, val_acc: 0.6531
Epoch [15/50], Loss: 0.0165, val_loss: 0.0147, val_acc: 0.6971
Epoch [16/50], Loss: 0.0149, val_loss: 0.0125, val_acc: 0.7273
Epoch [17/50], Loss: 0.0145, val_loss: 0.0127, val_acc: 0.7351
Epoch [18/50], Loss: 0.0134, val_loss: 0.0126, val_acc: 0.7610
Epoch [19/50], Loss: 0.0131, val_loss: 0.0122, val_acc: 0.7751
Epoch [20/50], Loss: 0.0126, val_loss: 0.0127, val_acc: 0.7543
Epoch [21/50], Loss: 0.0126, val_loss: 0.0130, val_acc: 0.7538
Epoch [22/50], Loss: 0.0120, val_loss: 0.0187, val_acc: 0.6467
Epoch [23/50], Loss: 0.0120, val_loss: 0.0128, val_acc: 0.7614
Epoch [24/50], Loss: 0.0113, val_loss: 0.0119, val_acc: 0.7837
Epoch [25/50], Loss: 0.0111, val_loss: 0.0143, val_acc: 0.7548
Epoch [26/50], Loss: 0.0107, val_loss: 0.0129, val_acc: 0.7562
Epoch [27/50], Loss: 0.0104, val_loss: 0.0113, val_acc: 0.7900
Epoch [28/50], Loss: 0.0105, val_loss: 0.0126, val_acc: 0.7836
Epoch [29/50], Loss: 0.0102, val_loss: 0.0126, val_acc: 0.8028
Epoch [30/50], Loss: 0.0100, val_loss: 0.0132, val_acc: 0.7683
Epoch [31/50], Loss: 0.0093, val_loss: 0.0175, val_acc: 0.7723
Epoch [32/50], Loss: 0.0093, val_loss: 0.0142, val_acc: 0.7911
Epoch [33/50], Loss: 0.0091, val_loss: 0.0120, val_acc: 0.8013
Epoch [34/50], Loss: 0.0096, val_loss: 0.0118, val_acc: 0.8033
Epoch [35/50], Loss: 0.0087, val_loss: 0.0111, val_acc: 0.8158
Epoch [36/50], Loss: 0.0083, val_loss: 0.0115, val_acc: 0.7977
Epoch [37/50], Loss: 0.0082, val_loss: 0.0112, val_acc: 0.8275
Epoch [38/50], Loss: 0.0092, val_loss: 0.0153, val_acc: 0.7541
Epoch [39/50], Loss: 0.0083, val_loss: 0.0114, val_acc: 0.8256
Epoch [40/50], Loss: 0.0079, val_loss: 0.0123, val_acc: 0.8090
Epoch [41/50], Loss: 0.0078, val_loss: 0.0157, val_acc: 0.7890
Epoch [42/50], Loss: 0.0086, val_loss: 0.0115, val_acc: 0.8031
Epoch [43/50], Loss: 0.0074, val_loss: 0.0120, val_acc: 0.8092
Epoch [44/50], Loss: 0.0074, val_loss: 0.0146, val_acc: 0.7872
Epoch [45/50], Loss: 0.0073, val_loss: 0.0147, val_acc: 0.7698
Epoch [46/50], Loss: 0.0068, val_loss: 0.0124, val_acc: 0.8355
Epoch [47/50], Loss: 0.0074, val_loss: 0.0129, val_acc: 0.8252
Epoch [48/50], Loss: 0.0073, val_loss: 0.0125, val_acc: 0.8282
Epoch [49/50], Loss: 0.0078, val_loss: 0.0129, val_acc: 0.7972
Epoch [50/50], Loss: 0.0075, val_loss: 0.0111, val_acc: 0.8207
test_accuracy: 82.05 %
learning time: 796.900 [sec]

--------------------------------------------------------------

Batch Norms: Default(NoDropOut)  |  test_accuracy: 82.81 %  |  learning time: 791.156 [sec]
Batch Norms: 1DropOut  |  test_accuracy: 83.21 %  |  learning time: 793.910 [sec]
Batch Norms: 2DropOuts  |  test_accuracy: 82.05 %  |  learning time: 796.900 [sec]
170500096it [40:17, 70514.74it/s]   
