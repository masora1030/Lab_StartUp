## CIFAR10のデータセットとVGG16ネットワークを用いて、ネットワーク内のDrop out処理を行う回数と段階を変えながら、学習曲線比較を行った。

- 驚くことに、Drop out処理を減らせば減らすほど学習の収束が早く、accが高くなり、過学習が抑えられていた。
- Batch Norm処理とDrop out処理の相性が悪い？
- VGG16ネットワークにおけるDrop outは抜いたほうが良いのでは
