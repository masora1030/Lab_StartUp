0it [00:00, ?it/s]  0%|          | 0/9912422 [00:00<?, ?it/s]  0%|          | 16384/9912422 [00:00<01:43, 95996.90it/s]  0%|          | 49152/9912422 [00:00<01:25, 115952.18it/s]  1%|          | 98304/9912422 [00:00<01:08, 144234.47it/s]  2%|▏         | 212992/9912422 [00:00<00:50, 191419.32it/s]  4%|▍         | 434176/9912422 [00:01<00:36, 260040.06it/s]  9%|▉         | 876544/9912422 [00:01<00:25, 358495.39it/s] 18%|█▊        | 1753088/9912422 [00:01<00:16, 499987.08it/s] 36%|███▌      | 3522560/9912422 [00:01<00:09, 702145.03it/s] 56%|█████▋    | 5595136/9912422 [00:01<00:04, 982748.26it/s] 77%|███████▋  | 7602176/9912422 [00:01<00:01, 1364388.50it/s] 97%|█████████▋| 9576448/9912422 [00:01<00:00, 1868494.25it/s]9920512it [00:02, 4695842.36it/s]                             
0it [00:00, ?it/s]  0%|          | 0/28881 [00:00<?, ?it/s] 57%|█████▋    | 16384/28881 [00:00<00:00, 113377.71it/s]32768it [00:00, 66806.90it/s]                            
0it [00:00, ?it/s]  0%|          | 0/1648877 [00:00<?, ?it/s]  1%|          | 16384/1648877 [00:00<00:17, 94739.75it/s]  3%|▎         | 49152/1648877 [00:00<00:13, 115016.03it/s]  6%|▌         | 98304/1648877 [00:00<00:10, 143628.43it/s] 13%|█▎        | 212992/1648877 [00:00<00:07, 190720.75it/s] 26%|██▋       | 434176/1648877 [00:01<00:04, 259015.14it/s] 53%|█████▎    | 868352/1648877 [00:01<00:02, 357017.53it/s]1654784it [00:01, 1279927.11it/s]                           
0it [00:00, ?it/s]  0%|          | 0/4542 [00:00<?, ?it/s]8192it [00:00, 23628.63it/s]            Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw/train-images-idx3-ubyte.gz
Extracting ./data_mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw/train-labels-idx1-ubyte.gz
Extracting ./data_mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz
Extracting ./data_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz
Extracting ./data_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw
Processing...
Done!
train_dataset =  48000
valid_dataset =  12000
test_dataset =  10000
training start ...

Epoch [1/50], Loss: 0.0047, val_loss: 0.0022, val_acc: 0.9373
Epoch [2/50], Loss: 0.0021, val_loss: 0.0016, val_acc: 0.9543
Epoch [3/50], Loss: 0.0016, val_loss: 0.0014, val_acc: 0.9590
Epoch [4/50], Loss: 0.0014, val_loss: 0.0012, val_acc: 0.9643
Epoch [5/50], Loss: 0.0011, val_loss: 0.0011, val_acc: 0.9682
Epoch [6/50], Loss: 0.0010, val_loss: 0.0010, val_acc: 0.9710
Epoch [7/50], Loss: 0.0009, val_loss: 0.0009, val_acc: 0.9720
Epoch [8/50], Loss: 0.0008, val_loss: 0.0009, val_acc: 0.9744
Epoch [9/50], Loss: 0.0007, val_loss: 0.0008, val_acc: 0.9752
Epoch [10/50], Loss: 0.0007, val_loss: 0.0009, val_acc: 0.9742
Epoch [11/50], Loss: 0.0006, val_loss: 0.0008, val_acc: 0.9755
Epoch [12/50], Loss: 0.0006, val_loss: 0.0008, val_acc: 0.9780
Epoch [13/50], Loss: 0.0005, val_loss: 0.0008, val_acc: 0.9775
Epoch [14/50], Loss: 0.0005, val_loss: 0.0007, val_acc: 0.9788
Epoch [15/50], Loss: 0.0005, val_loss: 0.0008, val_acc: 0.9782
Epoch [16/50], Loss: 0.0004, val_loss: 0.0007, val_acc: 0.9791
Epoch [17/50], Loss: 0.0004, val_loss: 0.0007, val_acc: 0.9783
Epoch [18/50], Loss: 0.0004, val_loss: 0.0007, val_acc: 0.9780
Epoch [19/50], Loss: 0.0004, val_loss: 0.0007, val_acc: 0.9806
Epoch [20/50], Loss: 0.0004, val_loss: 0.0007, val_acc: 0.9812
Epoch [21/50], Loss: 0.0004, val_loss: 0.0007, val_acc: 0.9801
Epoch [22/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9799
Epoch [23/50], Loss: 0.0003, val_loss: 0.0006, val_acc: 0.9802
Epoch [24/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9803
Epoch [25/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9809
Epoch [26/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9795
Epoch [27/50], Loss: 0.0003, val_loss: 0.0006, val_acc: 0.9808
Epoch [28/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9800
Epoch [29/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9811
Epoch [30/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9813
Epoch [31/50], Loss: 0.0003, val_loss: 0.0006, val_acc: 0.9812
Epoch [32/50], Loss: 0.0003, val_loss: 0.0007, val_acc: 0.9806
Epoch [33/50], Loss: 0.0003, val_loss: 0.0006, val_acc: 0.9811
Epoch [34/50], Loss: 0.0003, val_loss: 0.0006, val_acc: 0.9818
Epoch [35/50], Loss: 0.0002, val_loss: 0.0007, val_acc: 0.9811
Epoch [36/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9812
Epoch [37/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9813
Epoch [38/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9808
Epoch [39/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9814
Epoch [40/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9819
Epoch [41/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9818
Epoch [42/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9812
Epoch [43/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9812
Epoch [44/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9817
Epoch [45/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9811
Epoch [46/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9807
Epoch [47/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9808
Epoch [48/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9821
Epoch [49/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9820
Epoch [50/50], Loss: 0.0002, val_loss: 0.0006, val_acc: 0.9828
test_accuracy: 98.24 %
learning time: 100.834 [sec]
